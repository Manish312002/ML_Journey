{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96b9bec",
   "metadata": {},
   "source": [
    "# Feature Extraction of Text Data: TF-IDF Vectorizer\n",
    "\n",
    "- The Mapping from textual data to real valued vectors is called feature extraction.\n",
    "- There are many ways to do this, but the most popular one is tf-idf vectorization\n",
    "- TF-IDF stands for Term Frequency-Inverse Document Frequency.\n",
    "- It is a numerical statistic that reflects how important a word is to a document in a collection or corpus.\n",
    "- This technique can be used as a general term frequency measure and also as an information retrieval (IR) metric.\n",
    "- Bag of Words(BOM): List of unique words in the text corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84386e8",
   "metadata": {},
   "source": [
    "- Term Frequency (TF): (Number of times terms t appears in a document)/(Total number of terms in the document)\n",
    "- Inverse Document Frequency (IDF): log(N/n) :-\n",
    "where N is the total number of the documents and n is the number of documents containing term t.\n",
    "- The IDF of rare word is High and IDF of common words are Low.\n",
    "- TF-IDF : TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ba16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b74cb59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mbhoi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a139f3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab8f8046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_news_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b580d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df56cbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ... label\n",
       "0   0  ...     1\n",
       "1   1  ...     0\n",
       "2   2  ...     1\n",
       "3   3  ...     1\n",
       "4   4  ...     1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93f62abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    10413\n",
       "0    10387\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95446918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d71585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values with empty string\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f3d4345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13eaef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the author name and news title\n",
    "df['content'] = df['author'] + \" \" + df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66c05289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    darrel lucu hous dem aid even see comey letter...\n",
       "1    daniel j flynn flynn hillari clinton big woman...\n",
       "2               consortiumnew com truth might get fire\n",
       "3    jessica purkiss civilian kill singl us airstri...\n",
       "4    howard portnoy iranian woman jail fiction unpu...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8e08f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['label'], axis=1)\n",
    "Y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86dca8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# stemming is the process of reducing a word to its root word\n",
    "# e.g:\n",
    "# actor, actress, acting -> act\n",
    "# running, runner, runners -> run\n",
    "\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f0fbbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    st_content = re.sub('[^A-Za-z]', ' ', content)\n",
    "    st_content = st_content.lower()\n",
    "    st_content = st_content.split()\n",
    "    st_content = [ps.stem(word) for word in st_content\n",
    "                  if word not in set(stopwords.words('english'))]\n",
    "    st_content = ' '.join(st_content)\n",
    "    return st_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca6c9b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51a8f85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        darrel lucu hous dem aid even see comey letter...\n",
      "1        daniel j flynn flynn hillari clinton big woman...\n",
      "2                   consortiumnew com truth might get fire\n",
      "3        jessica purkiss civilian kill singl us airstri...\n",
      "4        howard portnoy iranian woman jail fiction unpu...\n",
      "                               ...                        \n",
      "20795    jerom hudson rapper trump poster child white s...\n",
      "20796    benjamin hoffman n f l playoff schedul matchup...\n",
      "20797    michael j de la merc rachel abram maci said re...\n",
      "20798    alex ansari nato russia hold parallel exercis ...\n",
      "20799                            david swanson keep f aliv\n",
      "Name: content, Length: 20800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8d8beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['content'].values\n",
    "Y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7916a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['darrel lucu hous dem aid even see comey letter jason chaffetz tweet'\n",
      " 'daniel j flynn flynn hillari clinton big woman campu breitbart'\n",
      " 'consortiumnew com truth might get fire' ...\n",
      " 'michael j de la merc rachel abram maci said receiv takeov approach hudson bay new york time'\n",
      " 'alex ansari nato russia hold parallel exercis balkan'\n",
      " 'david swanson keep f aliv']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0822311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe51b354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715d5d0",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a0fc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the textual data to Feature vector\n",
    "vectorizer =TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f40b1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(X)\n",
    "\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa514648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 210687 stored elements and shape (20800, 17128)>\n",
      "  Coords\tValues\n",
      "  (0, 267)\t0.2701012497770876\n",
      "  (0, 2483)\t0.36765196867972083\n",
      "  (0, 2959)\t0.24684501285337127\n",
      "  (0, 3600)\t0.3598939188262558\n",
      "  (0, 3792)\t0.27053324808454915\n",
      "  (0, 4973)\t0.23331696690935097\n",
      "  (0, 7005)\t0.2187416908935914\n",
      "  (0, 7692)\t0.24785219520671598\n",
      "  (0, 8630)\t0.2921251408704368\n",
      "  (0, 8909)\t0.36359638063260746\n",
      "  (0, 13473)\t0.2565896679337956\n",
      "  (0, 15686)\t0.2848506356272864\n",
      "  (1, 1497)\t0.2939891562094648\n",
      "  (1, 1894)\t0.15521974226349364\n",
      "  (1, 2223)\t0.3827320386859759\n",
      "  (1, 2813)\t0.19094574062359204\n",
      "  (1, 3568)\t0.26373768806048464\n",
      "  (1, 5503)\t0.7143299355715573\n",
      "  (1, 6816)\t0.1904660198296849\n",
      "  (1, 16799)\t0.30071745655510157\n",
      "  (2, 2943)\t0.3179886800654691\n",
      "  (2, 3103)\t0.46097489583229645\n",
      "  (2, 5389)\t0.3866530551182615\n",
      "  (2, 5968)\t0.3474613386728292\n",
      "  (2, 9620)\t0.49351492943649944\n",
      "  :\t:\n",
      "  (20797, 3643)\t0.2115550061362374\n",
      "  (20797, 7042)\t0.21799048897828685\n",
      "  (20797, 8364)\t0.22322585870464115\n",
      "  (20797, 8988)\t0.36160868928090795\n",
      "  (20797, 9518)\t0.29542040034203126\n",
      "  (20797, 9588)\t0.17455348025522197\n",
      "  (20797, 10306)\t0.08038079000566466\n",
      "  (20797, 12138)\t0.24778257724396505\n",
      "  (20797, 12344)\t0.27263457663336677\n",
      "  (20797, 13122)\t0.24825263521976057\n",
      "  (20797, 14967)\t0.3115945315488075\n",
      "  (20797, 15295)\t0.08159261204402356\n",
      "  (20797, 16996)\t0.08315655906109998\n",
      "  (20798, 350)\t0.2844693781907258\n",
      "  (20798, 588)\t0.3112141524638974\n",
      "  (20798, 1125)\t0.4460515589182237\n",
      "  (20798, 5032)\t0.40837014502395297\n",
      "  (20798, 6889)\t0.3249628569429943\n",
      "  (20798, 10177)\t0.31924963701870285\n",
      "  (20798, 11052)\t0.4460515589182237\n",
      "  (20798, 13046)\t0.2236326748827061\n",
      "  (20799, 377)\t0.5677577267055112\n",
      "  (20799, 3623)\t0.37927626273066584\n",
      "  (20799, 8036)\t0.45983893273780013\n",
      "  (20799, 14852)\t0.5677577267055112\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd80d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
